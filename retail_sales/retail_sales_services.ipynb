{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import csv\n",
    "import zipfile\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "from bs4 import BeautifulSoup\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download raw files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this section to get the monthly zip. It can be run fairly harmlessly as it shouldnt overwrite old versions you have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_marts(save_path='../raw/retail_sales_services/marts/staging/'\n",
    "                  ,file_name='MARTS-mf.zip'):\n",
    "    urllib.request.urlretrieve(\n",
    "        'https://www.census.gov/econ/currentdata/datasets/MARTS-mf.zip'\n",
    "        ,save_path+file_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_save_and_parse_mrts(mrts_path='../raw/retail_sales_services/marts/staging/'\n",
    "                            ,file_name='MARTS-mf.zip'\n",
    "                            ,save_path='../raw/retail_sales_services/marts/releases/'):\n",
    "    zf = zipfile.ZipFile(mrts_path+file_name)\n",
    "    output=str(subprocess.check_output('unzip -l '+mrts_path+file_name\n",
    "                                ,shell=True),encoding='utf-8')\n",
    "    \n",
    "    file_context = []\n",
    "    for row in output.split('\\n')[3:-3]:\n",
    "        file_context.append(\n",
    "            pd.to_datetime(\n",
    "                row.strip().split('  ')[1].strip()\n",
    "            )\n",
    "        )\n",
    "    max_date = str(np.max(file_context))[:10].replace('-','_')\n",
    "    \n",
    "    save_path = save_path+'{}'.format(max_date)\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(save_path)\n",
    "    except:\n",
    "        ''\n",
    "        \n",
    "    sections = []\n",
    "    with zf.open('README') as f:\n",
    "        for row in f:\n",
    "            if ' Section' in str(row):\n",
    "                sections.append(str(row,'utf-8').replace(' Section','').strip())        \n",
    "                \n",
    "    path=save_path\n",
    "    with zf.open('MARTS-mf.csv') as f:\n",
    "        martsreader = csv.reader(io.TextIOWrapper(f,'utf8'), delimiter=','\n",
    "                                ,quotechar='\"',quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "        for line in martsreader:\n",
    "            if len(line)==1:\n",
    "                strip_value = line[0].strip()\n",
    "            else:\n",
    "                strip_value=''\n",
    "            if strip_value in sections:\n",
    "                name=strip_value.lower().replace(' ','_')\n",
    "                try:\n",
    "                    csvfile.close()\n",
    "                except:\n",
    "                    ''\n",
    "                csvfile=open(path+name+'.csv','w')\n",
    "                martswriter = csv.writer(csvfile,delimiter=',',quotechar='\"'\n",
    "                                        ,quoting=csv.QUOTE_MINIMAL)\n",
    "            else:\n",
    "                if len(line)>0:\n",
    "                    martswriter.writerow(line)\n",
    "\n",
    "    csvfile.close()                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with zf.open('README') as f:\n",
    "#     readmereader = csv.reader(io.TextIOWrapper(f,'utf8'), delimiter='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(str(\n",
    "#     io.BytesIO(\n",
    "#         zf.open('README').read()\n",
    "#     ).read()\n",
    "# ,'utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_raw_marts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_save_and_parse_mrts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../raw/retail_sales_services/marts/releases/{}'.format(max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get release history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_census_release_page(save_path='../raw/retail_sales_services/marts/releases/raw_release_history/meta/'\n",
    "                  ,file_name='historical_marts.html'):\n",
    "    urllib.request.urlretrieve(\n",
    "        'https://www2.census.gov/retail/releases/historical/marts/'\n",
    "        ,save_path+file_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_census_release_page(save_path='../raw/retail_sales_services/marts/releases/raw_release_history/meta/'\n",
    "                  ,file_name='historical_marts.html'):\n",
    "    soup = BeautifulSoup(open(save_path+file_name), \"html5lib\")\n",
    "    table_array=[]\n",
    "    start_append=False\n",
    "    for row in soup.find_all('table')[0].find_all('tr'):\n",
    "        if start_append:\n",
    "            current_row=[]\n",
    "            for cell in row.find_all('td')[1:-1]:\n",
    "                current_row.append(cell.text.strip())\n",
    "            table_array.append(current_row)\n",
    "        elif 'Parent Directory' in row.text:\n",
    "            start_append=True\n",
    "    all_files_df = pd.DataFrame(table_array[:-1],columns=['file_name','date_added','size'])\n",
    "    \n",
    "    all_files_df.loc[:,('file_type')]=all_files_df.loc[:,('file_name')].str.split('.').str[1]\n",
    "    \n",
    "    all_files_df.loc[:,('file_name_date')]=all_files_df.loc[:,('file_name')]\\\n",
    "    .apply(lambda x: re.sub('[^0-9]','', x))\\\n",
    "    .apply(lambda x: '20'+x[:2]+'-'+x[-2:] if (len(x)==4 and x[:2]<'40')\n",
    "          else ( '19'+x[:2]+'-'+x[-2:] if len(x)==4 else ''))    \n",
    "    \n",
    "    return all_files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retreve_save_release(file_name\n",
    "                         ,save_path='../raw/retail_sales_services/marts/releases/raw_release_history/files/'):\n",
    "    urllib.request.urlretrieve(\n",
    "        'https://www2.census.gov/retail/releases/historical/marts/{}'.format(file_name)\n",
    "        ,save_path+'{}'.format(file_name)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text_sic(text_file_path):\n",
    "    \n",
    "    table_dict={'1A':{0:[],1:[]},'1B':{0:[],1:[]}}\n",
    "    start_append=False\n",
    "    indices = [0,15,50,64,73]\n",
    "\n",
    "    position=-1\n",
    "    annual_fix=False\n",
    "    current_table=''\n",
    "    with open(text_file_path, encoding=\"latin-1\") as f:\n",
    "        for row in f:\n",
    "            \n",
    "            if '12 month total' in row:\n",
    "                annual_fix=True\n",
    "            if row.strip()[:5]=='TABLE':\n",
    "                start_append=False\n",
    "                if '1A' in row and not annual_fix:\n",
    "                    current_table='1A'\n",
    "                    position=-1\n",
    "                    sales_as_of=pd.to_datetime(row.strip().split('--')[-1])\n",
    "                elif '1B' in row and not annual_fix:\n",
    "                    current_table='1B'\n",
    "                    position=-1\n",
    "                else:\n",
    "                    break\n",
    "                \n",
    "            if len(row.strip())>0 and row.strip()[0] in ['2','1'] and len(row[0].strip())==0 and not annual_fix:\n",
    "                position=position+1\n",
    "                table_dict[current_table][position]=[]\n",
    "                start_append=False\n",
    "            \n",
    "\n",
    "\n",
    "            if 'Retail trade, total' in row:                \n",
    "                if annual_fix:\n",
    "                    start_append=False\n",
    "                    annual_fix=False\n",
    "                else:\n",
    "                    start_append=True\n",
    "            \n",
    "            if start_append:\n",
    "#                print(row)\n",
    "                table_dict[current_table][position].append(row)\n",
    "\n",
    "            if row.strip()[:3]=='594':\n",
    "                start_append=False\n",
    "#    return table_dict\n",
    "    split_position_dict={'1A':{},'1B':{}}\n",
    "    for key in table_dict:\n",
    "        for sub_key in table_dict[key]:\n",
    "            split_position_dict[key][sub_key]=\\\n",
    "                max([x.rfind('...')+3 for x in table_dict[key][sub_key] if len(x)>0])\n",
    "    \n",
    "    for key in table_dict:\n",
    "        for sub_key in table_dict[key]:\n",
    "            fix_array=[]\n",
    "            for row in table_dict[key][sub_key]:\n",
    "                left=row[:split_position_dict[key][sub_key]]\n",
    "                right=row[split_position_dict[key][sub_key]:]\n",
    "                if len(left.strip())>0 or len(right.strip())>0:\n",
    "                    fix_array.append([\n",
    "                        left]+\\\n",
    "                        [x.strip() for x in right.split(' ') if len(x.strip())>0]\n",
    "                    )\n",
    "            table_dict[key][sub_key]=fix_array\n",
    "            \n",
    "    split_first_array_dict={'1A':{},'1B':{}}\n",
    "    for key in table_dict:\n",
    "        for sub_key in table_dict[key]:\n",
    "            left=[x[0] for x in table_dict[key][sub_key]]\n",
    "            split_first_array_dict[key][sub_key]=\\\n",
    "                max([len(re.search(re.compile(\"(?s:.*)[0-9]\"), x).group()) for x in left\n",
    "                    if re.search(re.compile(\"(?s:.*)[0-9]\"), x)])\n",
    "\n",
    "\n",
    "    for key in table_dict:\n",
    "        for sub_key in table_dict[key]:\n",
    "            fix_array=[]            \n",
    "            for row in table_dict[key][sub_key]:\n",
    "                left=row[0][:split_first_array_dict[key][sub_key]]\n",
    "                right=row[0][split_first_array_dict[key][sub_key]:]\n",
    "                temp =[left,right]+row[1:]\n",
    "                temp = [x.strip() for x in temp]\n",
    "                temp[1]=temp[1].replace('u\"\\u2026\"','').rstrip('.')\n",
    "                temp= temp[:2]+[x.replace(',','') for x in temp[2:]]\n",
    "                \n",
    "                fix_array.append(temp)\n",
    "            \n",
    "            table_dict[key][sub_key]=copy.deepcopy(fix_array)\n",
    "\n",
    "    df_1A_0=pd.DataFrame(table_dict['1A'][0],columns=[\n",
    "        'sic','description'\n",
    "        ,sales_as_of\n",
    "        ,sales_as_of-DateOffset(months=1)\n",
    "        ,sales_as_of-DateOffset(months=2)]).set_index(['sic','description']).stack().reset_index()    \n",
    "    df_1A_0.columns=['sic','description','as_of_date','value']\n",
    "    df_1A_0.loc[:,('is_sa')]=1\n",
    "\n",
    "    df_1A_1=pd.DataFrame(table_dict['1A'][1],columns=[\n",
    "        'sic','description'\n",
    "        ,sales_as_of-DateOffset(years=1)\n",
    "        ,sales_as_of-DateOffset(months=1)-DateOffset(years=1)\n",
    "        ]).set_index(['sic','description']).stack().reset_index()\n",
    "    df_1A_1.columns=['sic','description','as_of_date','value']\n",
    "    df_1A_1.loc[:,('is_sa')]=1\n",
    "\n",
    "    df_1B_0=pd.DataFrame(table_dict['1B'][0],columns=[\n",
    "        'sic','description'\n",
    "        ,sales_as_of\n",
    "        ,sales_as_of-DateOffset(months=1)\n",
    "        ,sales_as_of-DateOffset(months=2)]).set_index(['sic','description']).stack().reset_index()\n",
    "    df_1B_0.columns=['sic','description','as_of_date','value']\n",
    "    df_1B_0.loc[:,('is_sa')]=0\n",
    "\n",
    "    df_1B_1=pd.DataFrame(table_dict['1B'][1],columns=[\n",
    "        'sic','description'\n",
    "        ,sales_as_of-DateOffset(years=1)\n",
    "        ,sales_as_of-DateOffset(months=1)-DateOffset(years=1)\n",
    "    ]).set_index(['sic','description']).stack().reset_index()\n",
    "    df_1B_1.columns=['sic','description','as_of_date','value']\n",
    "    df_1B_1.loc[:,('is_sa')]=1        \n",
    "    \n",
    "    all_output=pd.concat([df_1A_0,df_1A_1,df_1B_0,df_1B_1])\n",
    "    all_output=all_output.query('value!=\"(NA)\"')\n",
    "#    all_output.loc[:,('value')]=all_output.loc[:,('value')].apply(lambda x: float(x) if x!='(*)' else float('NaN')).copy()\n",
    "    all_output.loc[:,('release_as_of_date')]=sales_as_of\n",
    "    return all_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_census_release_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names=parse_census_release_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_files = file_names.query('file_type==\"txt\"').sort_values('file_name_date')#\\\n",
    "#['file_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=0\n",
    "# for name in all_text_files:\n",
    "#     print(name)\n",
    "#     time.sleep(2)    \n",
    "#     retreve_save_release(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [],
   "source": [
    "sic_second_format=\\\n",
    "    all_text_files.query('file_name_date>=\"1999-01\" and file_name_date<=\"2001-04\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1284,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/tools/datetimes.py:116: FutureWarning: In the future, 'NAT == x' and 'x == NAT' will always be False.\n",
      "  unique_elements = set(islice(arg, check_count))\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "sic_second_format=\\\n",
    "    all_text_files.query('file_name_date>=\"1994-01\" and file_name_date<=\"2001-04\"')\n",
    "i=0\n",
    "for name in sic_second_format['file_name']:\n",
    "#    print(name)\n",
    "    save_path_string='../raw/retail_sales_services/marts/releases/raw_release_history/files/'\n",
    "    current_df = parse_text_sic(save_path_string+name)\n",
    "    \n",
    "    if i==0:\n",
    "        final_all_release=current_df.copy()\n",
    "        i=i+1\n",
    "    else:\n",
    "        final_all_release=pd.concat([final_all_release,current_df.copy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1285,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_all_release.to_csv('../cleaned/retail_sales_services/marts/sic_history.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text_naics(text_file_path):\n",
    "    \n",
    "    table_dict={'1A':[],'1B':[]}\n",
    "    start_append=False\n",
    "\n",
    "#    annual_fix=False\n",
    "    current_table=''\n",
    "    with open(text_file_path, encoding=\"latin-1\") as f:\n",
    "        for row in f:\n",
    "            \n",
    "\n",
    "            if row.strip()[:5] in ['TABLE','TTABL'] or '1B.  ESTIMATED MONTHLY SALES FOR RETAIL AND FOOD SERVICES' in row:\n",
    "                start_append=False\n",
    "                if '1A' in row:\n",
    "                    current_table='1A'\n",
    "                    sales_as_of=pd.to_datetime(row.strip().split('--')[-1])\n",
    "                elif '1B' in row:\n",
    "                    current_table='1B'\n",
    "                else:\n",
    "                    break            \n",
    "\n",
    "\n",
    "            if 'Retail & food services, total' in row:\n",
    "                start_append=True\n",
    "            \n",
    "            if start_append:\n",
    "                table_dict[current_table].append(row)\n",
    "\n",
    "            if row.strip()[:3]=='722':\n",
    "                start_append=False\n",
    "\n",
    "    split_position_dict={'1A':{},'1B':{}}\n",
    "    for key in table_dict:\n",
    "        split_position_dict[key]=\\\n",
    "            max([x.rfind('...')+3 for x in table_dict[key] if len(x)>0])\n",
    "    \n",
    "    \n",
    "    for key in table_dict:\n",
    "        fix_array=[]\n",
    "        for row in table_dict[key]:\n",
    "            left=row[:split_position_dict[key]]\n",
    "            right=row[split_position_dict[key]:]\n",
    "            if len(left.strip())>0 or len(right.strip())>0:\n",
    "                fix_array.append([\n",
    "                        re.sub(r'\\([0-9]\\)', '', left)]+\\\n",
    "                        [x.strip() for x in right.split(' ') if len(x.strip())>0]\n",
    "                    )\n",
    "            table_dict[key]=fix_array\n",
    "\n",
    "    split_first_array_dict={'1A':{},'1B':{}}\n",
    "    for key in table_dict:\n",
    "        left=[x[0] for x in table_dict[key]]\n",
    "        split_first_array_dict[key]=\\\n",
    "                max([len(re.search(re.compile(\"(?s:.*)[0-9]\"), x).group()) for x in left\n",
    "                    if re.search(re.compile(\"(?s:.*)[0-9]\"), x)])\n",
    "\n",
    "    for key in table_dict:\n",
    "        fix_array=[]            \n",
    "        for row in table_dict[key]:\n",
    "            left=row[0][:split_first_array_dict[key]]\n",
    "            right=row[0][split_first_array_dict[key]:]\n",
    "            temp =[left,right]+row[1:]\n",
    "            temp = [x.strip() for x in temp]\n",
    "            temp[1]=temp[1].replace('u\"\\u2026\"','').rstrip('.')\n",
    "            temp= temp[:2]+[x.replace(',','') for x in temp[2:]]\n",
    "                \n",
    "            fix_array.append(temp)\n",
    "            \n",
    "        table_dict[key]=fix_array\n",
    "        \n",
    "    df_1A=pd.DataFrame(table_dict['1A'],columns=[\n",
    "        'naics','description'\n",
    "        ,sales_as_of\n",
    "        ,sales_as_of-DateOffset(months=1)\n",
    "        ,sales_as_of-DateOffset(months=2)        \n",
    "        ,sales_as_of-DateOffset(years=1)\n",
    "        ,sales_as_of-DateOffset(years=1)-DateOffset(months=1)        \n",
    "    ]).set_index(['naics','description']).stack().reset_index()    \n",
    "    df_1A.columns=['naics','description','as_of_date','value']\n",
    "    df_1A.loc[:,('is_sa')]=1\n",
    "\n",
    "    df_1B=pd.DataFrame(table_dict['1B'],columns=[\n",
    "        'naics','description'\n",
    "        ,'year'\n",
    "        ,'pct_change_from_prior'\n",
    "        ,sales_as_of\n",
    "        ,sales_as_of-DateOffset(months=1)\n",
    "        ,sales_as_of-DateOffset(months=2)        \n",
    "        ,sales_as_of-DateOffset(years=1)\n",
    "        ,sales_as_of-DateOffset(years=1)-DateOffset(months=1)        \n",
    "    ]).set_index(['naics','description']).drop(['year','pct_change_from_prior'],axis=1)\\\n",
    "    .stack().reset_index()    \n",
    "    \n",
    "    df_1B.columns=['naics','description','as_of_date','value']\n",
    "    df_1B.loc[:,('is_sa')]=0        \n",
    "    \n",
    "    all_output=pd.concat([df_1A,df_1B])\n",
    "    all_output=all_output.query('value!=\"(NA)\"')\n",
    "#    all_output.loc[:,('value')]=all_output.loc[:,('value')].apply(lambda x: float(x) if x!='(*)' else float('NaN')).copy()\n",
    "    all_output.loc[:,('release_as_of_date')]=sales_as_of\n",
    "    return all_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs0105.txt\n",
      "rs0106.txt\n",
      "rs0107.txt\n",
      "rs0108.txt\n",
      "rs0109.txt\n",
      "rs0110.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/tools/datetimes.py:116: FutureWarning: In the future, 'NAT == x' and 'x == NAT' will always be False.\n",
      "  unique_elements = set(islice(arg, check_count))\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs0111.txt\n",
      "rs0112.txt\n",
      "rs0201.txt\n",
      "rs0202.txt\n",
      "rs0203.txt\n",
      "rs0204.txt\n",
      "rs0205.txt\n",
      "rs0206.txt\n",
      "rs0207.txt\n",
      "rs0208.txt\n",
      "rs0209.txt\n",
      "rs0210.txt\n",
      "rs0211.txt\n",
      "rs0212.txt\n",
      "rs0301.txt\n",
      "rs0302.txt\n",
      "rs0303.txt\n",
      "rs0304.txt\n",
      "rs0305.txt\n",
      "rs0306.txt\n",
      "rs0307.txt\n",
      "rs0308.txt\n",
      "rs0309.txt\n",
      "rs0310.txt\n",
      "rs0311.txt\n",
      "rs0312.txt\n",
      "rs0401.txt\n",
      "rs0402.txt\n",
      "rs0403.txt\n",
      "rs0404.txt\n",
      "rs0405.txt\n",
      "rs0406.txt\n",
      "rs0407.txt\n",
      "rs0408.txt\n",
      "rs0409.txt\n",
      "rs0410.txt\n",
      "rs0411.txt\n",
      "rs0412.txt\n",
      "rs0501.txt\n",
      "rs0502.txt\n",
      "rs0503.txt\n",
      "rs0504.txt\n",
      "rs0505.txt\n",
      "rs0506.txt\n",
      "rs0507.txt\n",
      "rs0508.txt\n",
      "rs0509.txt\n",
      "rs0510.txt\n",
      "rs0511.txt\n",
      "rs0512.txt\n",
      "rs0601.txt\n",
      "rs0602.txt\n",
      "rs0603.txt\n",
      "rs0604.txt\n",
      "rs0605.txt\n",
      "rs0606.txt\n",
      "rs0607.txt\n",
      "rs0608.txt\n",
      "rs0609.txt\n",
      "rs0610.txt\n",
      "rs0611.txt\n",
      "rs0612.txt\n",
      "rs0701.txt\n",
      "rs0702.txt\n",
      "rs0703.txt\n",
      "rs0704.txt\n",
      "rs0705.txt\n",
      "rs0706.txt\n",
      "rs0707.txt\n",
      "rs0708.txt\n",
      "rs0709.txt\n",
      "rs0710.txt\n",
      "rs0711.txt\n",
      "rs0712.txt\n",
      "rs0801.txt\n",
      "rs0802.txt\n",
      "rs0803.txt\n",
      "rs0804.txt\n",
      "rs0805.txt\n",
      "rs0806.txt\n",
      "rs0807.txt\n",
      "rs0808.txt\n",
      "rs0809.txt\n",
      "rs0810.txt\n",
      "rs0811.txt\n",
      "rs0812.txt\n",
      "rs0901.txt\n",
      "rs0902.txt\n",
      "rs0903.txt\n",
      "rs0904.txt\n",
      "rs0905.txt\n",
      "rs0906.txt\n",
      "rs0907.txt\n",
      "rs0908.txt\n",
      "rs0909.txt\n",
      "rs0910.txt\n",
      "rs0911.txt\n",
      "rs0912.txt\n",
      "rs1001.txt\n",
      "rs1002.txt\n",
      "rs1003.txt\n",
      "rs1004.txt\n",
      "rs1005.txt\n",
      "rs1006.txt\n",
      "rs1007.txt\n",
      "rs1008.txt\n",
      "rs1009.txt\n",
      "rs1010.txt\n",
      "rs1011.txt\n",
      "rs1012.txt\n",
      "rs1101.txt\n",
      "rs1102.txt\n",
      "rs1103.txt\n",
      "rs1104.txt\n",
      "rs1105.txt\n",
      "rs1106.txt\n",
      "rs1107.txt\n",
      "rs1108.txt\n",
      "rs1109.txt\n",
      "rs1110.txt\n",
      "rs1111.txt\n",
      "rs1112.txt\n",
      "rs1201.txt\n",
      "rs1202.txt\n",
      "rs1203.txt\n",
      "rs1204.txt\n",
      "rs1205.txt\n",
      "rs1206.txt\n",
      "rs1207.txt\n",
      "rs1208.txt\n",
      "rs1209.txt\n",
      "rs1210.txt\n",
      "rs1211.txt\n",
      "rs1212.txt\n"
     ]
    }
   ],
   "source": [
    "naics_format=\\\n",
    "    all_text_files.query('file_name_date>\"2001-04\"')\n",
    "i=0\n",
    "for name in naics_format['file_name']:\n",
    "    print(name)\n",
    "    save_path_string='../raw/retail_sales_services/marts/releases/raw_release_history/files/'\n",
    "    current_df = parse_text_naics(save_path_string+name)\n",
    "    \n",
    "    if i==0:\n",
    "        final_all_release=current_df.copy()\n",
    "        i=i+1\n",
    "    else:\n",
    "        final_all_release=pd.concat([final_all_release,current_df.copy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GAFO'"
      ]
     },
     "execution_count": 1244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1282,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_all_release.to_csv('../cleaned/retail_sales_services/marts/naics_history.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naics</th>\n",
       "      <th>description</th>\n",
       "      <th>as_of_date</th>\n",
       "      <th>value</th>\n",
       "      <th>is_sa</th>\n",
       "      <th>release_as_of_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Retail &amp; food services, total</td>\n",
       "      <td>2001-05-01</td>\n",
       "      <td>291306</td>\n",
       "      <td>1</td>\n",
       "      <td>2001-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Retail &amp; food services, total</td>\n",
       "      <td>2001-04-01</td>\n",
       "      <td>291090</td>\n",
       "      <td>1</td>\n",
       "      <td>2001-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Retail &amp; food services, total</td>\n",
       "      <td>2001-03-01</td>\n",
       "      <td>287102</td>\n",
       "      <td>1</td>\n",
       "      <td>2001-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Retail &amp; food services, total</td>\n",
       "      <td>2000-05-01</td>\n",
       "      <td>280547</td>\n",
       "      <td>1</td>\n",
       "      <td>2001-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>Retail &amp; food services, total</td>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>279961</td>\n",
       "      <td>1</td>\n",
       "      <td>2001-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>722</td>\n",
       "      <td>Food services &amp; drinking places</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>45671</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>722</td>\n",
       "      <td>Food services &amp; drinking places</td>\n",
       "      <td>2012-11-01</td>\n",
       "      <td>42964</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>722</td>\n",
       "      <td>Food services &amp; drinking places</td>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>44077</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>722</td>\n",
       "      <td>Food services &amp; drinking places</td>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>43010</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>722</td>\n",
       "      <td>Food services &amp; drinking places</td>\n",
       "      <td>2011-11-01</td>\n",
       "      <td>39755</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-12-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49491 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    naics                      description as_of_date   value  is_sa  \\\n",
       "0            Retail & food services, total 2001-05-01  291306      1   \n",
       "1            Retail & food services, total 2001-04-01  291090      1   \n",
       "2            Retail & food services, total 2001-03-01  287102      1   \n",
       "3            Retail & food services, total 2000-05-01  280547      1   \n",
       "4            Retail & food services, total 2000-04-01  279961      1   \n",
       "..    ...                              ...        ...     ...    ...   \n",
       "185   722  Food services & drinking places 2012-12-01   45671      0   \n",
       "186   722  Food services & drinking places 2012-11-01   42964      0   \n",
       "187   722  Food services & drinking places 2012-10-01   44077      0   \n",
       "188   722  Food services & drinking places 2011-12-01   43010      0   \n",
       "189   722  Food services & drinking places 2011-11-01   39755      0   \n",
       "\n",
       "    release_as_of_date  \n",
       "0           2001-05-01  \n",
       "1           2001-05-01  \n",
       "2           2001-05-01  \n",
       "3           2001-05-01  \n",
       "4           2001-05-01  \n",
       "..                 ...  \n",
       "185         2012-12-01  \n",
       "186         2012-12-01  \n",
       "187         2012-12-01  \n",
       "188         2012-12-01  \n",
       "189         2012-12-01  \n",
       "\n",
       "[49491 rows x 6 columns]"
      ]
     },
     "execution_count": 1281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_all_release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
