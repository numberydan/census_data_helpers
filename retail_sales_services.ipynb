{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import csv\n",
    "import zipfile\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "from bs4 import BeautifulSoup\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download raw files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this section to get the monthly zip. It can be run fairly harmlessly as it shouldnt overwrite old versions you have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_marts(save_path='../raw/retail_sales_services/marts/staging/'\n",
    "                  ,file_name='MARTS-mf.zip'):\n",
    "    urllib.request.urlretrieve(\n",
    "        'https://www.census.gov/econ/currentdata/datasets/MARTS-mf.zip'\n",
    "        ,save_path+file_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_save_and_parse_mrts(mrts_path='../raw/retail_sales_services/marts/staging/'\n",
    "                            ,file_name='MARTS-mf.zip'\n",
    "                            ,save_path='../raw/retail_sales_services/marts/releases/'):\n",
    "    zf = zipfile.ZipFile(mrts_path+file_name)\n",
    "    output=str(subprocess.check_output('unzip -l '+mrts_path+file_name\n",
    "                                ,shell=True),encoding='utf-8')\n",
    "    \n",
    "    file_context = []\n",
    "    for row in output.split('\\n')[3:-3]:\n",
    "        file_context.append(\n",
    "            pd.to_datetime(\n",
    "                row.strip().split('  ')[1].strip()\n",
    "            )\n",
    "        )\n",
    "    max_date = str(np.max(file_context))[:10].replace('-','_')\n",
    "    \n",
    "    save_path = save_path+'{}'.format(max_date)\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(save_path)\n",
    "    except:\n",
    "        ''\n",
    "        \n",
    "    sections = []\n",
    "    with zf.open('README') as f:\n",
    "        for row in f:\n",
    "            if ' Section' in str(row):\n",
    "                sections.append(str(row,'utf-8').replace(' Section','').strip())        \n",
    "                \n",
    "    path=save_path\n",
    "    with zf.open('MARTS-mf.csv') as f:\n",
    "        martsreader = csv.reader(io.TextIOWrapper(f,'utf8'), delimiter=','\n",
    "                                ,quotechar='\"',quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "        for line in martsreader:\n",
    "            if len(line)==1:\n",
    "                strip_value = line[0].strip()\n",
    "            else:\n",
    "                strip_value=''\n",
    "            if strip_value in sections:\n",
    "                name=strip_value.lower().replace(' ','_')\n",
    "                try:\n",
    "                    csvfile.close()\n",
    "                except:\n",
    "                    ''\n",
    "                csvfile=open(path+name+'.csv','w')\n",
    "                martswriter = csv.writer(csvfile,delimiter=',',quotechar='\"'\n",
    "                                        ,quoting=csv.QUOTE_MINIMAL)\n",
    "            else:\n",
    "                if len(line)>0:\n",
    "                    martswriter.writerow(line)\n",
    "\n",
    "    csvfile.close()                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with zf.open('README') as f:\n",
    "#     readmereader = csv.reader(io.TextIOWrapper(f,'utf8'), delimiter='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(str(\n",
    "#     io.BytesIO(\n",
    "#         zf.open('README').read()\n",
    "#     ).read()\n",
    "# ,'utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_raw_marts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_save_and_parse_mrts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../raw/retail_sales_services/marts/releases/{}'.format(max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get release history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_census_release_page(save_path='../raw/retail_sales_services/marts/releases/raw_release_history/meta/'\n",
    "                  ,file_name='historical_marts.html'):\n",
    "    urllib.request.urlretrieve(\n",
    "        'https://www2.census.gov/retail/releases/historical/marts/'\n",
    "        ,save_path+file_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_census_release_page(save_path='../raw/retail_sales_services/marts/releases/raw_release_history/meta/'\n",
    "                  ,file_name='historical_marts.html'):\n",
    "    soup = BeautifulSoup(open(save_path+file_name), \"html5lib\")\n",
    "    table_array=[]\n",
    "    start_append=False\n",
    "    for row in soup.find_all('table')[0].find_all('tr'):\n",
    "        if start_append:\n",
    "            current_row=[]\n",
    "            for cell in row.find_all('td')[1:-1]:\n",
    "                current_row.append(cell.text.strip())\n",
    "            table_array.append(current_row)\n",
    "        elif 'Parent Directory' in row.text:\n",
    "            start_append=True\n",
    "    all_files_df = pd.DataFrame(table_array[:-1],columns=['file_name','date_added','size'])\n",
    "    \n",
    "    all_files_df.loc[:,('file_type')]=all_files_df.loc[:,('file_name')].str.split('.').str[1]\n",
    "    \n",
    "    all_files_df.loc[:,('file_name_date')]=all_files_df.loc[:,('file_name')]\\\n",
    "    .apply(lambda x: re.sub('[^0-9]','', x))\\\n",
    "    .apply(lambda x: '20'+x[:2]+'-'+x[-2:] if (len(x)==4 and x[:2]<'40')\n",
    "          else ( '19'+x[:2]+'-'+x[-2:] if len(x)==4 else ''))    \n",
    "    \n",
    "    return all_files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retreve_save_release(file_name\n",
    "                         ,save_path='../raw/retail_sales_services/marts/releases/raw_release_history/files/'):\n",
    "    urllib.request.urlretrieve(\n",
    "        'https://www2.census.gov/retail/releases/historical/marts/{}'.format(file_name)\n",
    "        ,save_path+'{}'.format(file_name)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text_sic(text_file_path):\n",
    "    \n",
    "    table_dict={'1A':{0:[],1:[]},'1B':{0:[],1:[]}}\n",
    "    start_append=False\n",
    "    indices = [0,15,50,64,73]\n",
    "\n",
    "    position=-1\n",
    "    annual_fix=False\n",
    "    current_table=''\n",
    "    with open(text_file_path, encoding=\"latin-1\") as f:\n",
    "        for row in f:\n",
    "            \n",
    "            if '12 month total' in row:\n",
    "                annual_fix=True\n",
    "            if row.strip()[:5]=='TABLE':\n",
    "                start_append=False\n",
    "                if '1A' in row and not annual_fix:\n",
    "                    current_table='1A'\n",
    "                    position=-1\n",
    "                    sales_as_of=pd.to_datetime(row.strip().split('--')[-1])\n",
    "                elif '1B' in row and not annual_fix:\n",
    "                    current_table='1B'\n",
    "                    position=-1\n",
    "                else:\n",
    "                    break\n",
    "                \n",
    "            if len(row.strip())>0 and row.strip()[0] in ['2','1'] and len(row[0].strip())==0 and not annual_fix:\n",
    "                position=position+1\n",
    "                table_dict[current_table][position]=[]\n",
    "                start_append=False\n",
    "            \n",
    "\n",
    "\n",
    "            if 'Retail trade, total' in row:                \n",
    "                if annual_fix:\n",
    "                    start_append=False\n",
    "                    annual_fix=False\n",
    "                else:\n",
    "                    start_append=True\n",
    "            \n",
    "            if start_append:\n",
    "#                print(row)\n",
    "                table_dict[current_table][position].append(row)\n",
    "\n",
    "            if row.strip()[:3]=='594':\n",
    "                start_append=False\n",
    "#    return table_dict\n",
    "    split_position_dict={'1A':{},'1B':{}}\n",
    "    for key in table_dict:\n",
    "        for sub_key in table_dict[key]:\n",
    "            split_position_dict[key][sub_key]=\\\n",
    "                max([x.rfind('...')+3 for x in table_dict[key][sub_key] if len(x)>0])\n",
    "    \n",
    "    for key in table_dict:\n",
    "        for sub_key in table_dict[key]:\n",
    "            fix_array=[]\n",
    "            for row in table_dict[key][sub_key]:\n",
    "                left=row[:split_position_dict[key][sub_key]]\n",
    "                right=row[split_position_dict[key][sub_key]:]\n",
    "                if len(left.strip())>0 or len(right.strip())>0:\n",
    "                    fix_array.append([\n",
    "                        left]+\\\n",
    "                        [x.strip() for x in right.split(' ') if len(x.strip())>0]\n",
    "                    )\n",
    "            table_dict[key][sub_key]=fix_array\n",
    "            \n",
    "    split_first_array_dict={'1A':{},'1B':{}}\n",
    "    for key in table_dict:\n",
    "        for sub_key in table_dict[key]:\n",
    "            left=[x[0] for x in table_dict[key][sub_key]]\n",
    "            split_first_array_dict[key][sub_key]=\\\n",
    "                max([len(re.search(re.compile(\"(?s:.*)[0-9]\"), x).group()) for x in left\n",
    "                    if re.search(re.compile(\"(?s:.*)[0-9]\"), x)])\n",
    "\n",
    "\n",
    "    for key in table_dict:\n",
    "        for sub_key in table_dict[key]:\n",
    "            fix_array=[]            \n",
    "            for row in table_dict[key][sub_key]:\n",
    "                left=row[0][:split_first_array_dict[key][sub_key]]\n",
    "                right=row[0][split_first_array_dict[key][sub_key]:]\n",
    "                temp =[left,right]+row[1:]\n",
    "                temp = [x.strip() for x in temp]\n",
    "                temp[1]=temp[1].replace('u\"\\u2026\"','').rstrip('.')\n",
    "                temp= temp[:2]+[x.replace(',','') for x in temp[2:]]\n",
    "                \n",
    "                fix_array.append(temp)\n",
    "            \n",
    "            table_dict[key][sub_key]=copy.deepcopy(fix_array)\n",
    "\n",
    "    df_1A_0=pd.DataFrame(table_dict['1A'][0],columns=[\n",
    "        'sic','description'\n",
    "        ,sales_as_of\n",
    "        ,sales_as_of-DateOffset(months=1)\n",
    "        ,sales_as_of-DateOffset(months=2)]).set_index(['sic','description']).stack().reset_index()    \n",
    "    df_1A_0.columns=['sic','description','as_of_date','value']\n",
    "    df_1A_0.loc[:,('is_sa')]=1\n",
    "\n",
    "    df_1A_1=pd.DataFrame(table_dict['1A'][1],columns=[\n",
    "        'sic','description'\n",
    "        ,sales_as_of-DateOffset(years=1)\n",
    "        ,sales_as_of-DateOffset(months=1)-DateOffset(years=1)\n",
    "        ]).set_index(['sic','description']).stack().reset_index()\n",
    "    df_1A_1.columns=['sic','description','as_of_date','value']\n",
    "    df_1A_1.loc[:,('is_sa')]=1\n",
    "\n",
    "    df_1B_0=pd.DataFrame(table_dict['1B'][0],columns=[\n",
    "        'sic','description'\n",
    "        ,sales_as_of\n",
    "        ,sales_as_of-DateOffset(months=1)\n",
    "        ,sales_as_of-DateOffset(months=2)]).set_index(['sic','description']).stack().reset_index()\n",
    "    df_1B_0.columns=['sic','description','as_of_date','value']\n",
    "    df_1B_0.loc[:,('is_sa')]=0\n",
    "\n",
    "    df_1B_1=pd.DataFrame(table_dict['1B'][1],columns=[\n",
    "        'sic','description'\n",
    "        ,sales_as_of-DateOffset(years=1)\n",
    "        ,sales_as_of-DateOffset(months=1)-DateOffset(years=1)\n",
    "    ]).set_index(['sic','description']).stack().reset_index()\n",
    "    df_1B_1.columns=['sic','description','as_of_date','value']\n",
    "    df_1B_1.loc[:,('is_sa')]=1        \n",
    "    \n",
    "    all_output=pd.concat([df_1A_0,df_1A_1,df_1B_0,df_1B_1])\n",
    "    all_output=all_output.query('value!=\"(NA)\"')\n",
    "#    all_output.loc[:,('value')]=all_output.loc[:,('value')].apply(lambda x: float(x) if x!='(*)' else float('NaN')).copy()\n",
    "    all_output.loc[:,('release_as_of_date')]=sales_as_of\n",
    "    return all_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_census_release_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names=parse_census_release_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_files = file_names.query('file_type==\"txt\"').sort_values('file_name_date')#\\\n",
    "#['file_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=0\n",
    "# for name in all_text_files:\n",
    "#     print(name)\n",
    "#     time.sleep(2)    \n",
    "#     retreve_save_release(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [],
   "source": [
    "sic_second_format=\\\n",
    "    all_text_files.query('file_name_date>=\"1999-01\" and file_name_date<=\"2001-04\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/tools/datetimes.py:116: FutureWarning: In the future, 'NAT == x' and 'x == NAT' will always be False.\n",
      "  unique_elements = set(islice(arg, check_count))\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "sic_second_format=\\\n",
    "    all_text_files.query('file_name_date>=\"1994-01\" and file_name_date<=\"2001-04\"')\n",
    "i=0\n",
    "for name in sic_second_format['file_name']:\n",
    "#    print(name)\n",
    "    save_path_string='../raw/retail_sales_services/marts/releases/raw_release_history/files/'\n",
    "    current_df = parse_text_sic(save_path_string+name)\n",
    "    \n",
    "    if i==0:\n",
    "        final_all_release=current_df.copy()\n",
    "        i=i+1\n",
    "    else:\n",
    "        final_all_release=pd.concat([final_all_release,current_df.copy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_all_release.to_csv('../cleaned/retail_sales_services/marts/sic_history.txt',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
